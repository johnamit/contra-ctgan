{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance, entropy, pearsonr, gaussian_kde\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein Distance\n",
    "def compute_wasserstein_distance(real_data, synthetic_data):\n",
    "    \"\"\"Compute Wasserstein Distance for all numerical features.\"\"\"\n",
    "    WS_distance_list = []\n",
    "    for col in real_data.columns:\n",
    "        if np.issubdtype(real_data[col].dtype, np.number):  # Check if the column is numerical\n",
    "            wsd = wasserstein_distance(real_data[col].dropna().values, synthetic_data[col].dropna().values) # compute WSD\n",
    "            WS_distance_list.append(wsd)\n",
    "    return np.mean(WS_distance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Jensen-Shannon Divergence (JSD) - for categorical data\n",
    "# def compute_jsd_categorical(real_data, synthetic_data):\n",
    "#     \"\"\"Compute Jensen-Shannon Divergence (JSD) for all categorical features.\"\"\"\n",
    "#     jsd_list = []\n",
    "#     for col in real_data.columns:\n",
    "#         if not np.issubdtype(real_data[col].dtype, np.number): # categorical only\n",
    "#             real_freq = real_data[col].value_counts(normalize=True).sort_index()\n",
    "#             synth_freq = synthetic_data[col].value_counts(normalize=True).sort_index()\n",
    "            \n",
    "#             # Align the distributions to the same set of categories\n",
    "#             all_categories = real_freq.index.union(synth_freq.index)\n",
    "#             real_prob = real_freq.reindex(all_categories, fill_value=0).values\n",
    "#             synth_prob = synth_freq.reindex(all_categories, fill_value=0).values\n",
    "            \n",
    "#             # Compute Jensen-Shannon Divergence (distance)\n",
    "#             jsd = jensenshannon(real_prob, synth_prob, base=2)\n",
    "#             jsd_list[col] = jsd\n",
    "#     return np.mean(jsd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jensen-Shannon Divergence (JSD) - for numerical data\n",
    "def compute_jsd_numerical(real_data, synthetic_data, bins=50):\n",
    "    \"\"\"Compute Jensen-Shannon Divergence (JSD) for all numerical features.\"\"\"\n",
    "    jsd_list = []\n",
    "    for col in real_data.columns:\n",
    "        if np.issubdtype(real_data[col].dtype, np.number): # numerical only\n",
    "            real_hist, bin_edges = np.histogram(real_data[col], bins=bins, density=True)\n",
    "            synthetic_hist, _ = np.histogram(synthetic_data[col], bins=bin_edges, density=True)\n",
    "\n",
    "            # Normalize to probability distributions\n",
    "            real_prob = real_hist / np.sum(real_hist)\n",
    "            synthetic_prob = synthetic_hist / np.sum(synthetic_hist)\n",
    "\n",
    "            # Compute JSD\n",
    "            jsd = jensenshannon(real_prob, synthetic_prob, base=2)\n",
    "            jsd_list.append(jsd)\n",
    "    return np.mean(jsd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 distance between Pearson correlation matrices (Numerical)\n",
    "def compute_l2dist_pearson(real_data, synthetic_data):\n",
    "    \"\"\"Compute L2 distance between Pearson correlation matrices.\"\"\"\n",
    "    numerical_cols = real_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    real_corr = real_data[numerical_cols].corr()\n",
    "    synthetic_corr = synthetic_data[numerical_cols].corr()\n",
    "\n",
    "    # # flatten the correlation matrices\n",
    "    # real_corr = real_corr.values.flatten()\n",
    "    # synthetic_corr = synthetic_corr.values.flatten()\n",
    "\n",
    "    l2_distance = np.linalg.norm(real_corr.values.flatten() - synthetic_corr.values.flatten())\n",
    "    return l2_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_classification(training_data, holdout_data, target):\n",
    "    \"\"\"Train an XGBoost classifier on the provided data and evaluate on the holdout set.\"\"\"\n",
    "    X_holdout = holdout_data.drop(columns=[target])\n",
    "    y_holdout = holdout_data[target]\n",
    "\n",
    "    X_train = training_data.drop(columns=[target])\n",
    "    y_train = training_data[target]\n",
    "\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_holdout) \n",
    "    y_proba = model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_holdout, y_pred),\n",
    "        \"auc\": roc_auc_score(y_holdout, y_proba),\n",
    "        \"f1\": f1_score(y_holdout, y_pred),\n",
    "        \"precision\": precision_score(y_holdout, y_pred),\n",
    "        \"recall\": recall_score(y_holdout, y_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_holdout, y_pred)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models and prep synthetic data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.read_csv('Datasets/creditcard_train.csv')\n",
    "target_col = 'Class'\n",
    "discrete_columns = [\"Class\"]\n",
    "holdout_data = pd.read_csv('Datasets/creditcard_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data saved at SyntheticDatasets/Eval/synthetic_data_BASECTGAN_EVAL.csv\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "import torch\n",
    "from ctgan import CTGAN, TVAE\n",
    "from Scripts.contrastive_ctgan import ContrastiveCTGAN, Embedder\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_samples = real_data.shape[0]\n",
    "\n",
    "# CTGAN Initialization and Data Generation\n",
    "ctgan_path = \"Models/BaselineCTGAN.pth\"\n",
    "ctgan_model = torch.load(ctgan_path, weights_only=False)\n",
    "# Generate synthetic data with CTGAN (Baseline)\n",
    "synth_data = ctgan_model.sample(num_samples)\n",
    "synthetic_data_path = 'SyntheticDatasets/Eval/synthetic_data_BASECTGAN_EVAL.csv'\n",
    "pd.DataFrame(synth_data).to_csv(synthetic_data_path, index=False)\n",
    "print(f\"Synthetic data saved at {synthetic_data_path}\")\n",
    "\n",
    "\n",
    "# TVAE Initialization and Data Generation\n",
    "tvae_model = TVAE(epochs=300, batch_size=500, cuda=True)\n",
    "tvae_model.fit(real_data)\n",
    "# Generate synthetic data with TVAE (Baseline).\n",
    "synth_data_tvae = tvae_model.sample(num_samples)\n",
    "synthetic_data_tvae_path = 'SyntheticDatasets/Eval/synthetic_data_TVAE_EVAL.csv'\n",
    "pd.DataFrame(synth_data_tvae).to_csv(synthetic_data_tvae_path, index=False)\n",
    "print(f\"Synthetic data saved at {synthetic_data_tvae_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9996\n",
      "Auc: 0.9777\n",
      "F1: 0.899\n",
      "Precision: 0.957\n",
      "Recall: 0.8476\n",
      "Confusion_matrix: [[56852     4]\n",
      " [   16    89]]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56852     4]\n",
      " [   16    89]]\n"
     ]
    }
   ],
   "source": [
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(real_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics[\"confusion_matrix\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CTGAN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Baseline CTGAN ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 167.65606352345813\n",
      "JSD (numerical): 0.198252741102858\n",
      "L2 Distance Pearson Correlation: 8.194095499106425\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9792\n",
      "Auc: 0.9762\n",
      "F1: 0.1392\n",
      "Precision: 0.0754\n",
      "Recall: 0.9143\n",
      "Confusion_matrix: [[55678  1178]\n",
      " [    9    96]]\n"
     ]
    }
   ],
   "source": [
    "# Load the synthetic data generated by CTGAN (BASELINE)\n",
    "synth_data = pd.read_csv('SyntheticDatasets/Eval/synthetic_data_BASECTGAN_EVAL.csv')\n",
    "\n",
    "print(\"--------- Baseline CTGAN ---------\")\n",
    "\n",
    "# Data Fidelity\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data)}\")\n",
    "# print(f\"JSD (categorical): {compute_jsd_categorical(real_data, synth_data)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data)}\")\n",
    "\n",
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(synth_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline TVAE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- TVAE ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 240.7881261661354\n",
      "JSD (numerical): 0.163311066577089\n",
      "L2 Distance Pearson Correlation: nan\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9982\n",
      "Auc: 0.5\n",
      "F1: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Confusion_matrix: [[56856     0]\n",
      " [  105     0]]\n"
     ]
    }
   ],
   "source": [
    "# Load the synthetic data generated by TVAE\n",
    "synth_data_tvae = pd.read_csv('SyntheticDatasets/Eval/synthetic_data_TVAE_EVAL.csv')\n",
    "\n",
    "print(\"--------- TVAE ---------\")\n",
    "\n",
    "# Data Fidelity Metrics:\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data_tvae)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data_tvae)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data_tvae)}\")\n",
    "\n",
    "# Data Utility Metrics:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics_tvae = downstream_classification(synth_data_tvae, holdout_data, target_col)\n",
    "for metric, value in metrics_tvae.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContraCTGAN (Lambda 0.5, Temp 0.5) Evaluation [Best Model So Far]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ContraCTGAN (Lambda 0.5, Temp 0.5) ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 109.73358401517287\n",
      "JSD (numerical): 0.19841696736554457\n",
      "L2 Distance Pearson Correlation: 7.736916446568145\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9919\n",
      "Auc: 0.9673\n",
      "F1: 0.2883\n",
      "Precision: 0.1718\n",
      "Recall: 0.8952\n",
      "Confusion_matrix: [[56403   453]\n",
      " [   11    94]]\n"
     ]
    }
   ],
   "source": [
    "synth_data = pd.read_csv('SyntheticDatasets/synthetic_data_ContrastiveCTGAN_lambda0_5_temp0_5.csv') \n",
    "\n",
    "print(\"--------- ContraCTGAN (Lambda 0.5, Temp 0.5) ---------\")\n",
    "\n",
    "# Data Fidelity\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data)}\")\n",
    "# print(f\"JSD (categorical): {compute_jsd_categorical(real_data, synth_data)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data)}\")\n",
    "\n",
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(synth_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContraCTGAN (Lambda 0.5, Temp 0.1) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ContraCTGAN (Lambda 0.5, Temp 0.1) ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 122.52302629002686\n",
      "JSD (numerical): 0.20565993878865202\n",
      "L2 Distance Pearson Correlation: 8.183968862790755\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9894\n",
      "Auc: 0.9774\n",
      "F1: 0.2418\n",
      "Precision: 0.1393\n",
      "Recall: 0.9143\n",
      "Confusion_matrix: [[56263   593]\n",
      " [    9    96]]\n"
     ]
    }
   ],
   "source": [
    "# Load the synthetic data generated by ContraCTGAN (Lambda 0.5, Temp 0.1)\n",
    "synth_data = pd.read_csv('SyntheticDatasets/synthetic_data_contrastive_ctgan_full_hpt_corrected.csv') \n",
    "\n",
    "print(\"--------- ContraCTGAN (Lambda 0.5, Temp 0.1) ---------\")\n",
    "\n",
    "# Data Fidelity\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data)}\")\n",
    "# print(f\"JSD (categorical): {compute_jsd_categorical(real_data, synth_data)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data)}\")\n",
    "\n",
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(synth_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContraCTGAN (Lambda 0.2, Temp 1.0) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ContraCTGAN (Lambda 0.2, Temp 1.0) ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 187.76774679887382\n",
      "JSD (numerical): 0.20332505692723915\n",
      "L2 Distance Pearson Correlation: 7.921025555365883\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9931\n",
      "Auc: 0.9808\n",
      "F1: 0.316\n",
      "Precision: 0.1932\n",
      "Recall: 0.8667\n",
      "Confusion_matrix: [[56476   380]\n",
      " [   14    91]]\n"
     ]
    }
   ],
   "source": [
    "synth_data = pd.read_csv('SyntheticDatasets/synthetic_data_ContrastiveCTGAN_lambda0_2_temp1_0.csv') \n",
    "\n",
    "print(\"--------- ContraCTGAN (Lambda 0.2, Temp 1.0) ---------\")\n",
    "\n",
    "# Data Fidelity\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data)}\")\n",
    "# print(f\"JSD (categorical): {compute_jsd_categorical(real_data, synth_data)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data)}\")\n",
    "\n",
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(synth_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContraCTGAN (Lambda 0.8, Temp 0.8) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ContraCTGAN (Lambda 0.8, Temp 0.8) ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 81.33844724624835\n",
      "JSD (numerical): 0.1995632958651905\n",
      "L2 Distance Pearson Correlation: 8.56982301290151\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.9884\n",
      "Auc: 0.969\n",
      "F1: 0.2259\n",
      "Precision: 0.1289\n",
      "Recall: 0.9143\n",
      "Confusion_matrix: [[56207   649]\n",
      " [    9    96]]\n"
     ]
    }
   ],
   "source": [
    "synth_data = pd.read_csv('SyntheticDatasets/synthetic_data_ContrastiveCTGAN_lambda0_8_temp0_8.csv') \n",
    "\n",
    "print(\"--------- ContraCTGAN (Lambda 0.8, Temp 0.8) ---------\")\n",
    "\n",
    "# Data Fidelity\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data)}\")\n",
    "# print(f\"JSD (categorical): {compute_jsd_categorical(real_data, synth_data)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data)}\")\n",
    "\n",
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(synth_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContraCTGAN (Lambda 1.0, Temp 0.07) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ContraCTGAN (Lambda 1.0, Temp 0.07) ---------\n",
      "Data Fidelity Metrics:\n",
      "WSD (numerical): 96.34658901639892\n",
      "JSD (numerical): 0.19800927092971657\n",
      "L2 Distance Pearson Correlation: 7.9728675952997206\n",
      "\n",
      "Data Utility Metrics:\n",
      "Accuracy: 0.987\n",
      "Auc: 0.9773\n",
      "F1: 0.2019\n",
      "Precision: 0.1138\n",
      "Recall: 0.8952\n",
      "Confusion_matrix: [[56124   732]\n",
      " [   11    94]]\n"
     ]
    }
   ],
   "source": [
    "synth_data = pd.read_csv('SyntheticDatasets/synthetic_data_ContrastiveCTGAN_lambda1_0_temp0_07.csv') \n",
    "\n",
    "print(\"--------- ContraCTGAN (Lambda 1.0, Temp 0.07) ---------\")\n",
    "\n",
    "# Data Fidelity\n",
    "print(\"Data Fidelity Metrics:\")\n",
    "print(f\"WSD (numerical): {compute_wasserstein_distance(real_data, synth_data)}\")\n",
    "# print(f\"JSD (categorical): {compute_jsd_categorical(real_data, synth_data)}\")\n",
    "print(f\"JSD (numerical): {compute_jsd_numerical(real_data, synth_data)}\")\n",
    "print(f\"L2 Distance Pearson Correlation: {compute_l2dist_pearson(real_data, synth_data)}\")\n",
    "\n",
    "# Data Utility:\n",
    "print(\"\\nData Utility Metrics:\")\n",
    "metrics = downstream_classification(synth_data, holdout_data, target_col)\n",
    "for metric, value in metrics.items():\n",
    "    rounded_value = np.round(value, 4) if isinstance(value, np.ndarray) else round(value, 4)\n",
    "    print(f\"{metric.capitalize()}: {rounded_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advfinance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
